{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "https://blog.csdn.net/m0_46413065/article/details/129917287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g2 = pd.read_csv(\"./Data/Kaohsiung/g2.csv\",delimiter=';')\n",
    "data_g3 = pd.read_csv(\"./Data/Kaohsiung/g3.csv\",delimiter=';')\n",
    "data_g4 = pd.read_csv(\"./Data/Kaohsiung/g4.csv\",delimiter=';')\n",
    "data = [data_g2]\n",
    "\n",
    "features = ['date_time']\n",
    "targets = ['E', 'N', 'H']\n",
    "group_id_i = 2\n",
    "\n",
    "for i in range(1):\n",
    "    data[i]['date_time'] = pd.to_datetime(data[i]['date_time'])\n",
    "    data[i]['date_time'] = data[i]['date_time'].astype(int) / (10 ** 11)\n",
    "    data[i]['date_time'] = data[i]['date_time'].astype(int)\n",
    "    data[i] = data[i][features+targets]\n",
    "    #data[i]['group_id'] = group_id_i\n",
    "    group_id_i += 1\n",
    "    \n",
    "data = pd.concat(data,ignore_index=True)\n",
    "data['group_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>H</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17055522</td>\n",
       "      <td>224095.7991</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.4140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17055528</td>\n",
       "      <td>224095.7980</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.4135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17055744</td>\n",
       "      <td>224095.7973</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.3954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17055750</td>\n",
       "      <td>224095.8001</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.3838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17055762</td>\n",
       "      <td>224095.8011</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.3934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_time            E             N          H  group_id\n",
       "0   17055522  224095.7991  2.551570e+06  1518.4140         0\n",
       "1   17055528  224095.7980  2.551570e+06  1518.4135         0\n",
       "2   17055744  224095.7973  2.551570e+06  1518.3954         0\n",
       "3   17055750  224095.8001  2.551570e+06  1518.3838         0\n",
       "4   17055762  224095.8011  2.551570e+06  1518.3934         0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>H</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31179</th>\n",
       "      <td>17355504</td>\n",
       "      <td>224095.7558</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.5164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31180</th>\n",
       "      <td>17355510</td>\n",
       "      <td>224095.7558</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.5165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31181</th>\n",
       "      <td>17355516</td>\n",
       "      <td>224095.7561</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.5175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31182</th>\n",
       "      <td>17355522</td>\n",
       "      <td>224095.7536</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.5217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31183</th>\n",
       "      <td>17355600</td>\n",
       "      <td>224095.7455</td>\n",
       "      <td>2.551570e+06</td>\n",
       "      <td>1518.5070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_time            E             N          H  group_id\n",
       "31179   17355504  224095.7558  2.551570e+06  1518.5164         0\n",
       "31180   17355510  224095.7558  2.551570e+06  1518.5165         0\n",
       "31181   17355516  224095.7561  2.551570e+06  1518.5175         0\n",
       "31182   17355522  224095.7536  2.551570e+06  1518.5217         0\n",
       "31183   17355600  224095.7455  2.551570e+06  1518.5070         0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import MultiNormalizer,TorchNormalizer\n",
    "\n",
    "max_prediction_length = 7#*144\n",
    "max_encoder_length = 7*144\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[:len(data)-max_prediction_length],\n",
    "    group_ids = [\"group_id\"],\n",
    "    target = targets,\n",
    "    time_idx = \"date_time\",\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_encoder_length=max_encoder_length//2,  # 似乎要自己設置(默認值好像太大?)\n",
    "    min_prediction_length=1,  #同上\n",
    "    time_varying_unknown_reals = targets,\n",
    "    target_normalizer=MultiNormalizer([TorchNormalizer() for _ in targets]),\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training,data,predict=True,stop_randomization=True)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = training.to_dataloader(train=True,batch_size=batch_size,num_workers=4)\n",
    "val_dataloader = validation.to_dataloader(train=False,batch_size=batch_size*10,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/undergrad/miniconda3/envs/114/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/undergrad/miniconda3/envs/114/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for each target: [0.0, 2327474.25, 222577.234375]\n"
     ]
    }
   ],
   "source": [
    "# from pytorch_forecasting import Baseline\n",
    "\n",
    "# actuals = torch.cat([y[0] for x, (y,weight) in iter(val_dataloader)])\n",
    "# baseline_predictions = Baseline().predict(val_dataloader)\n",
    "# # 假設你希望將 `baseline_predictions` 移動到相同的設備\n",
    "# baseline_predictions = baseline_predictions.to(actuals.device)\n",
    "\n",
    "# # 現在兩者在相同設備上，可以進行計算\n",
    "# result = (actuals - baseline_predictions).abs().mean().item()\n",
    "\n",
    "from pytorch_forecasting import Baseline\n",
    "\n",
    "# 取得 `actuals`，支援多個 target\n",
    "actuals = torch.cat([y if isinstance(y, torch.Tensor) else y[0] for x, (y, weight) in iter(val_dataloader)])\n",
    "\n",
    "# 獲取 baseline 預測值\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "\n",
    "# 確保 `baseline_predictions` 是 tensor\n",
    "if isinstance(baseline_predictions, list):\n",
    "    baseline_predictions = torch.stack(baseline_predictions, dim=1)  # 確保維度對應\n",
    "\n",
    "# 確保 baseline_predictions 在相同設備\n",
    "baseline_predictions = baseline_predictions.to(actuals.device)\n",
    "\n",
    "# 計算 MAE\n",
    "result = (actuals - baseline_predictions).abs().mean(dim=[0, 2])  # 針對每個 target 計算 MAE\n",
    "print(\"MAE for each target:\", result.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | MultiLoss                       | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0      | train\n",
      "3  | prescalers                         | ModuleDict                      | 320    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 12.1 K | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 36.9 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 0      | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 40.6 K | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 40.6 K | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 40.6 K | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 40.6 K | train\n",
      "11 | lstm_encoder                       | LSTM                            | 80.8 K | train\n",
      "12 | lstm_decoder                       | LSTM                            | 80.8 K | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 20.2 K | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 200    | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 50.6 K | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 25.2 K | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 20.4 K | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 40.6 K | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 20.4 K | train\n",
      "20 | output_layer                       | ModuleList                      | 303    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "550 K     Trainable params\n",
      "0         Non-trainable params\n",
      "550 K     Total params\n",
      "2.204     Total estimated model params size (MB)\n",
      "195       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  25%|██▌       | 292/1150 [30:09<1:28:36,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [30:09<1:28:37,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [30:09<1:28:37,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [30:09<1:28:37,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]\n",
      "Epoch 0: 100%|██████████| 1150/1150 [01:21<00:00, 14.19it/s, v_num=9, train_loss_step=0.0144, val_loss=0.0344, train_loss_epoch=0.0263]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  25%|██▌       | 292/1150 [31:11<1:31:38,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040] \n",
      "Epoch 16:  25%|██▌       | 292/1150 [31:11<1:31:38,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [31:11<1:31:39,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [31:11<1:31:39,  0.16it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040] \n",
      "Epoch 1: 100%|██████████| 1150/1150 [01:21<00:00, 14.16it/s, v_num=9, train_loss_step=0.0182, val_loss=0.0171, train_loss_epoch=0.0162] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0001. New best score: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  25%|██▌       | 292/1150 [32:17<1:34:54,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [32:17<1:34:54,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040] \n",
      "Epoch 16:  25%|██▌       | 292/1150 [32:18<1:34:54,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [32:18<1:34:54,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]]\n",
      "Epoch 2: 100%|██████████| 1150/1150 [01:21<00:00, 14.17it/s, v_num=9, train_loss_step=0.0137, val_loss=0.00938, train_loss_epoch=0.0157]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0001. New best score: 0.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  25%|██▌       | 292/1150 [33:23<1:38:07,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]7]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [33:23<1:38:08,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]7]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [33:24<1:38:09,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]] \n",
      "Epoch 16:  25%|██▌       | 292/1150 [33:24<1:38:09,  0.15it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [34:30<1:41:23,  0.14it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]   \n",
      "Epoch 16:  25%|██▌       | 292/1150 [34:30<1:41:23,  0.14it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [34:30<1:41:23,  0.14it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [34:30<1:41:23,  0.14it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]\n",
      "Epoch 16:  25%|██▌       | 292/1150 [35:16<1:43:37,  0.14it/s, v_num=7, train_loss_step=3.980, val_loss=47.50, train_loss_epoch=9.040]]\n",
      "Epoch 5: 100%|██████████| 1150/1150 [01:21<00:00, 14.16it/s, v_num=9, train_loss_step=0.0077, val_loss=0.00799, train_loss_epoch=0.0141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1150/1150 [01:21<00:00, 14.15it/s, v_num=9, train_loss_step=0.0122, val_loss=0.00732, train_loss_epoch=0.0142] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1150/1150 [01:21<00:00, 14.15it/s, v_num=9, train_loss_step=0.00795, val_loss=0.00633, train_loss_epoch=0.0137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1150/1150 [01:21<00:00, 14.15it/s, v_num=9, train_loss_step=0.0115, val_loss=0.00572, train_loss_epoch=0.0131] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1150/1150 [01:21<00:00, 14.15it/s, v_num=9, train_loss_step=0.00451, val_loss=0.00696, train_loss_epoch=0.0132]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1150/1150 [01:21<00:00, 14.10it/s, v_num=9, train_loss_step=0.00451, val_loss=0.00696, train_loss_epoch=0.0132]\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting import TemporalFusionTransformer, QuantileLoss, MultiLoss\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\",min_delta=1e-4,patience=5,verbose=True,mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    accelerator = 'gpu',\n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    accumulate_grad_batches=4,\n",
    "    callbacks=[lr_logger,early_stop_callback],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.001,\n",
    "    hidden_size=100,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=40,\n",
    "    output_size=[1,1,1], #len(targets),\n",
    "    loss=MultiLoss([QuantileLoss(quantiles=[0.5]),QuantileLoss(quantiles=[0.5]),QuantileLoss(quantiles=[0.5])]),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning_logs/lightning_logs/version_9/checkpoints/epoch=14-step=4320.ckpt\n"
     ]
    }
   ],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "numpy() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#mae_T = mean_absolute_error(actuals, predictions)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#rmse_T = np.sqrt(mean_squared_error(actuals, predictions))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#print(mae_T,'\\n',rmse_T)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 对于每个目标，计算 MAE 和 RMSE\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# 假设 actuals 和 predictions 的形状是 (num_samples, num_targets)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     actual_target \u001b[38;5;241m=\u001b[39m \u001b[43mactuals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     predicted_target \u001b[38;5;241m=\u001b[39m predictions[target_idx]\n\u001b[1;32m     17\u001b[0m     mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(actual_target, predicted_target)\n",
      "\u001b[0;31mTypeError\u001b[0m: numpy() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "#actuals = torch.cat([y for x,y in iter(val_dataloader)]).cpu().numpy()\n",
    "actuals = torch.cat([y if isinstance(y, torch.Tensor) else y[0] for x, (y, weight) in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error \n",
    "\n",
    "#mae_T = mean_absolute_error(actuals, predictions)\n",
    "#rmse_T = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "\n",
    "#print(mae_T,'\\n',rmse_T)\n",
    "\n",
    "# 对于每个目标，计算 MAE 和 RMSE\n",
    "for target_idx in range(3):  # 假设 actuals 和 predictions 的形状是 (num_samples, num_targets)\n",
    "    actual_target = actuals[0,target_idx].cpu().numpy()\n",
    "    predicted_target = predictions[target_idx]\n",
    "\n",
    "    mae = mean_absolute_error(actual_target, predicted_target)\n",
    "    rmse = np.sqrt(mean_squared_error(actual_target, predicted_target))\n",
    "\n",
    "    print(f\"Target {target_idx + 1} MAE: {mae:.4f}\")\n",
    "    print(f\"Target {target_idx + 1} RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
