{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "https://blog.csdn.net/m0_46413065/article/details/129917287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import MultiNormalizer,TorchNormalizer,GroupNormalizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g2 = pd.read_csv(\"./Data/Nantou/cn01_scaled.csv\",delimiter=';')\n",
    "data = data_g2\n",
    "\n",
    "features = ['date_time']\n",
    "targets = ['EMove', 'NMove', 'HMove']\n",
    "\n",
    "data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "data['date_time'] = data['date_time'].astype('int64') / (10 ** 11)\n",
    "data['date_time'] = data['date_time'].astype('int64')\n",
    "\n",
    "\n",
    "data = data[features+targets]\n",
    "    \n",
    "data['group_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)  # Check all the columns in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "max_prediction_length = 4\n",
    "max_encoder_length =144\n",
    "# Assuming `data` is already preprocessed and scaled.\n",
    "train_data = data[:int(len(data)*0.8)]\n",
    "val_data = data[int(len(data)*0.8):int(len(data)*0.8)+int(len(data)*0.1)]\n",
    "test_data = data[int(len(data)*0.8)+int(len(data)*0.1):]\n",
    "\n",
    "# Define your TimeSeriesDataSet for training\n",
    "training = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    group_ids=[\"group_id\"],\n",
    "    target=targets,\n",
    "    time_idx=\"date_time\",\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_encoder_length=20,  # Set based on your needs\n",
    "    min_prediction_length=1,  # Same here\n",
    "    time_varying_unknown_reals=targets,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "# Define your TimeSeriesDataSet for validation\n",
    "validation = TimeSeriesDataSet(\n",
    "    val_data,\n",
    "    group_ids=[\"group_id\"],\n",
    "    target=targets,\n",
    "    time_idx=\"date_time\",\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_encoder_length=20,  # Adjust based on validation needs\n",
    "    #min_prediction_length=1,\n",
    "    time_varying_unknown_reals=targets,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "# Define your TimeSeriesDataSet for test\n",
    "test = TimeSeriesDataSet(\n",
    "    test_data,\n",
    "    group_ids=[\"group_id\"],\n",
    "    target=targets,\n",
    "    time_idx=\"date_time\",\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_encoder_length=20,  # Adjust based on validation needs\n",
    "    #min_prediction_length=1,\n",
    "    time_varying_unknown_reals=targets,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = training.to_dataloader(train=True,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "val_dataloader = validation.to_dataloader(train=False,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "test_dataloader = test.to_dataloader(train=False,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total dataset size: {len(data)}\")\n",
    "print(f\"Training size: {len(training)}\")\n",
    "print(f\"Validation size: {len(validation)}\")\n",
    "print(f\"Number of batches in val_dataloader: {len(val_dataloader)}\")\n",
    "print(f\"Length of validation dataset: {len(validation)}\")\n",
    "# for i, sample in enumerate(validation):\n",
    "#     print(i, sample)\n",
    "print(data[\"group_id\"].value_counts())  # See if some groups are too small\n",
    "actuals_list = []\n",
    "for batch in test_dataloader:\n",
    "    # actuals_list.append(batch[1][0][0])  # `batch[1]` contains actual target values\n",
    "    actuals_list.append(torch.stack(batch[1][0], dim=-1))  # Stack along last dimension\n",
    "\n",
    "# print(actuals_list)\n",
    "actuals = torch.cat(actuals_list, dim=0)  # Combine all batches\n",
    "actuals = actuals.permute(2, 0, 1)  # Switch dimensions\n",
    "\n",
    "print(actuals.shape)\n",
    "print(type(actuals))\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    print(type(batch[1]))   # Should show if it's a tuple\n",
    "    print(len(batch[1]))    # Check number of elements in the tuple\n",
    "    print(type(batch[1][0]))  # Check type of the first element\n",
    "    print(len(batch[1][0]))\n",
    "    print(batch[1][0][0].shape)  # Check shape of first element\n",
    "    break  # Only print first batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual values for each movement component\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.suptitle(\"Actual(blue) vs Predicted(red) Movements Over Time\", fontsize=16, fontweight='bold', y=1.02)\n",
    "n=max_prediction_length\n",
    "# For EMove (target 0)\n",
    "actuals_E = actuals[0,:,::n].cpu().numpy()\n",
    "testData=test_data['EMove'].values\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(actuals_E, label=\"Actual EMove\", color='blue')\n",
    "plt.plot(testData, label=\"Actual \", color='red')\n",
    "\n",
    "plt.title(\"E Move: Actual vs Predicted\")\n",
    "plt.ylim([np.min(actuals_E), np.max(actuals_E)])  # Set same y-axis range\n",
    "\n",
    "# For NMove (target 1)\n",
    "actuals_N = actuals[1,:,::n].cpu().numpy()\n",
    "testData=test_data['NMove'].values\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(actuals_N, label=\"Actual NMove\", color='blue')\n",
    "plt.plot(testData, label=\"Actual \", color='red')\n",
    "plt.title(\"N Move: Actual vs Predicted\")\n",
    "plt.ylim([np.min(actuals_N), np.max(actuals_N)])  # Set same y-axis range\n",
    "\n",
    "\n",
    "# For HMove (target 2)\n",
    "actuals_H = actuals[2,:,::n].cpu().numpy()\n",
    "testData=test_data['HMove'].values\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(actuals_H, label=\"Actual HMove\", color='blue')\n",
    "plt.plot(testData, label=\"Actual \", color='red')\n",
    "plt.title(\"H Move: Actual vs Predicted\")\n",
    "plt.ylim([np.min(actuals_H), np.max(actuals_H)])  # Set same y-axis range\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有問題，所以先跳過\n",
    "# from pytorch_forecasting import Baseline\n",
    "\n",
    "# # Retrieve actuals and ensure proper stacking\n",
    "# # actuals = torch.cat([\n",
    "# #     (y if isinstance(y, torch.Tensor) else y[0])  # Handling if `y` is a list or tensor\n",
    "# #     for x, (y, weight) in iter(val_dataloader)\n",
    "# # ], dim=0)\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# # Make sure that y is padded to the same length in each batch\n",
    "# y_padded = torch.stack([pad_sequence([torch.tensor(yi_i) for yi_i in yi], batch_first=True) for yi in y], dim=2)\n",
    "\n",
    "# # Concatenate actuals across batches\n",
    "# actuals = torch.cat([y_padded for x, (y, weight) in iter(val_dataloader)], dim=0)\n",
    "# actuals=actuals.transpose(2, 1)\n",
    "\n",
    "\n",
    "# # Get baseline predictions\n",
    "# baseline_predictions = Baseline().predict(val_dataloader)\n",
    "\n",
    "# # Ensure `baseline_predictions` is a tensor\n",
    "# if isinstance(baseline_predictions, list):\n",
    "#     baseline_predictions = torch.stack(baseline_predictions, dim=1)  # Stack if it's a list\n",
    "\n",
    "# # Ensure baseline_predictions is on the same device as actuals\n",
    "# baseline_predictions = baseline_predictions.to(actuals.device)\n",
    "\n",
    "# # Print shapes to debug\n",
    "# print(f\"Shape of actuals: {actuals.shape}\")\n",
    "# print(f\"Shape of baseline_predictions: {baseline_predictions.shape}\")\n",
    "\n",
    "# # Calculate MAE for each target (across all time steps for each target)\n",
    "# result = (actuals - baseline_predictions).abs().mean(dim=[0, 2])  # Compute MAE for each target\n",
    "\n",
    "# # Print MAE results\n",
    "# print(\"MAE for each target:\", result.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting import TemporalFusionTransformer, QuantileLoss, MultiLoss\n",
    "\n",
    "#5次loss改善小於1e-4時，停止訓練\n",
    "#目的是避免overfitting\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\",min_delta=1e-4,patience=5,verbose=True,mode=\"min\")\n",
    "#記錄學習率的變化\n",
    "lr_logger = LearningRateMonitor()\n",
    "#將訓練數據存入Lightning_logs資料夾\n",
    "logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15,  #最多訓練幾次\n",
    "    accelerator = 'gpu',    #用gpu訓練(加速)\n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,  #限制梯度最大值，避免梯度爆炸\n",
    "    accumulate_grad_batches=4,  #每4個batch累積梯度後，進行權重更新\n",
    "    callbacks=[lr_logger,early_stop_callback],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.005,\n",
    "    hidden_size=128,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.2,    #隨機丟棄30%神經元，避免overfitting\n",
    "    hidden_continuous_size=32,\n",
    "    optimizer=\"ranger\",   #優化器\n",
    "    output_size=[7,7,7], #len(targets),\n",
    "    loss=MultiLoss([QuantileLoss(),QuantileLoss(),QuantileLoss()]),\n",
    "    log_interval=10,    #每10 batch紀錄一次log\n",
    "    reduce_on_plateau_patience=2    #兩次沒有改善時調整學習率\n",
    ")\n",
    "\n",
    "import torch.nn.init as init\n",
    "def init_tft_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)  # Xavier 初始化\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "# 將初始化套用到 TFT 模型\n",
    "tft.apply(init_tft_weights)\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error \n",
    "\n",
    "predictions = best_tft.predict(test_dataloader)\n",
    "predictions = torch.stack(predictions)\n",
    "\n",
    "if isinstance(actuals, list):\n",
    "    actuals = torch.stack(actuals, dim=0)  # Stack along first dimension to form a tensor (shape: [3, batch_size, 144])\n",
    "\n",
    "\n",
    "print(type(predictions))\n",
    "print(type(actuals))\n",
    "\n",
    "# 对于每个目标，计算 MAE 和 RMSE\n",
    "for target_idx in range(3):  # 假设 actuals 和 predictions 的形状是 (num_samples, num_targets)\n",
    "    actual_target = actuals[target_idx, :, :].cpu().numpy()\n",
    "    predicted_target = predictions[target_idx, :, :].cpu().numpy()  # Ensure predictions have the same shape\n",
    "    # print(actual_target,'\\n',predicted_target)\n",
    "\n",
    "    mae = mean_absolute_error(actual_target, predicted_target)\n",
    "    rmse = np.sqrt(mean_squared_error(actual_target, predicted_target))\n",
    "\n",
    "    print(f\"Test {targets[target_idx]} MAE: {mae:.4f}\")\n",
    "    print(f\"Test {targets[target_idx]} RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot predictions vs actual values for each movement component\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.suptitle(\"Actual(blue) vs Predicted(red) Movements Over Time\", fontsize=16, fontweight='bold', y=1.02)\n",
    "n=max_prediction_length\n",
    "# For EMove (target 0)\n",
    "actuals_E = actuals[0,:,::n].cpu().numpy()\n",
    "predicted_E = predictions[0,:,::n].cpu().numpy()\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(actuals_E, label=\"Actual EMove\", color='blue')\n",
    "plt.plot(predicted_E, label=\"Predicted EMove\", color='red', linestyle='dashed')\n",
    "plt.title(\"E Move: Actual vs Predicted\")\n",
    "plt.ylim([np.min(actuals_E), np.max(actuals_E)])  # Set same y-axis range\n",
    "\n",
    "# For NMove (target 1)\n",
    "actuals_N = actuals[1,:,::n].cpu().numpy()\n",
    "predicted_N = predictions[1,:,::n].cpu().numpy()\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(actuals_N, label=\"Actual NMove\", color='blue')\n",
    "plt.plot(predicted_N ,label=\"Predicted NMove\", color='red', linestyle='dashed')\n",
    "plt.title(\"N Move: Actual vs Predicted\")\n",
    "plt.ylim([np.min(actuals_N), np.max(actuals_N)])  # Set same y-axis range\n",
    "\n",
    "\n",
    "# For HMove (target 2)\n",
    "actuals_H = actuals[2,:,::n].cpu().numpy()\n",
    "predicted_H = predictions[2,:,::n].cpu().numpy()\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(actuals_H, label=\"Actual HMove\", color='blue')\n",
    "plt.plot(predicted_H, label=\"Predicted HMove\", color='red', linestyle='dashed')\n",
    "plt.title(\"H Move: Actual vs Predicted\")\n",
    "plt.ylim([np.min(actuals_H), np.max(actuals_H)])  # Set same y-axis range\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
